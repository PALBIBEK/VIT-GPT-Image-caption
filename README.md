Developed an image captioning system combining Vision Transformer with a GPT-2 Decoder for state-of-the-art caption generation and InceptionV3 with LSTM for robust CNN-RNN based captioning. The project focuses on leveraging the strengths of both architectures to generate accurate and contextually rich image descriptions, with potential applications in real-time caption generation and multimodal embedding integration.
